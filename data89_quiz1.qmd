---
title: "Quiz 1 Findings"
author: Jonathan A. Pedroza
format:
  html:
    toc: true
    toc-depth: 2
    grid:
      #sidebar-width: 0px
      body-width: 1300px
      #margin-width: 0px
      gutter-width: 1.5rem
    theme: lumen
    code-fold: true
jupyter: python3
execute:
  echo: true
  eval: true
  warning: false
  message: false
params:
---

```{python}
#| tags: [parameters]

jpcolor = 'seagreen'
quiz_num = 'quiz1'
irt_num = '1'
dcm_type = 'lcdm'
mastery_prob = .8
prof_prob = .5
```

```{python}
import numpy as np
import pandas as pd
import plotnine as pn
from janitor import clean_names
from pyhere import here
import matplotlib
import matplotlib.pyplot as plt
import arviz as az
import joblib
from scipy import stats
import os
from cmdstanpy import CmdStanModel
from great_tables import GT as gt
import plotly.express as px
import plotly.io as pio

os.environ['QT_API'] = 'PyQt6'
pd.set_option('display.max_columns', None)
pd.options.mode.copy_on_write = True
matplotlib.rcParams.update({'savefig.bbox': 'tight'})
pn.theme_set(pn.theme_light())
# pio.templates.default = 'simple_white' # 'plotly_white'

def overall_ppp(df, stat):
    thresh = np.array(y_describe.loc[y_describe['index'] == stat, 'item1':'item10'].mean(axis = 1))[0]
    cond = df.loc[:, stat] > thresh
    ppp_val = np.where(cond, 1, 0).mean()
    return ppp_val

def ppp_func(df, item_num, stat):
    thresh = np.array(y_describe.loc[y_describe['index'] == stat, f'item{item_num}'])[0]
    cond = df.loc[df['item'] == item_num, stat] > thresh
    ppp_val = np.where(cond, 1, 0).mean()
    return ppp_val

def q_lower(x):
    return x.quantile(.025)
  
def q_upper(x):
    return x.quantile(.975)
```

```{python}
#| echo: false

# imported data
contact = pd.read_csv(here('fake_names_emails.csv'))
contact.head()

# correct/incorrect responses to each quiz item
y = pd.read_csv(here('data/quiz/y.csv')).drop(columns = {'Unnamed: 0'})
y['name'] = contact['name']

np.random.seed(12345)
y_sub = y.sample(n = 113)

# q-matrix
q = pd.read_csv(here('data/q_matrix/q.csv')).drop(columns = {'Unnamed: 0'})

# attribute mastery matrix
alpha = pd.DataFrame([(x, y) for x in np.arange(2) for y in np.arange(2)])
alpha = alpha.rename(columns = {0: 'hold1',
                                1: 'hold2'})

# stan dictionary data
irt_dict = {
  'J': y_sub.drop(columns = 'name').shape[0],
  'I': y_sub.drop(columns = 'name').shape[1],
  'Y': np.array(y_sub.drop(columns = 'name'))
}

y_describe = y_sub.filter(regex = 'item').agg(['mean', 'std']).reset_index()
y_describe.drop(columns = 'index').transpose()
actual_avg = y_describe.loc[y_describe['index'] == 'mean', 'item1':'item10'].mean(axis = 1)[0]
```

# IRT Model

```{python}
# irt_file = os.path.join(here('stan_models/irt_1pl.stan'))
irt_file = os.path.join(here('stan_models/irt_2pl.stan'))
# irt_file = os.path.join(here('stan_models/irt_3pl.stan'))

irt_model = CmdStanModel(stan_file = irt_file,
                         cpp_options = {'STAN_THREADS': 'TRUE'})
```

```{python}
#| include: false

#running bayesian IRT model
np.random.seed(12345)
irt_fit = irt_model.sample(data = irt_dict,
                        show_console = True,
                        chains = 4,
                        # adapt_delta = .95,
                        iter_warmup = 2000,
                        iter_sampling = 2000)

irt_diagnose = pd.DataFrame(irt_fit.summary())
```

```{python}
#| eval: false
#| echo: true

irt_diagnose.to_csv(here(f'diagnostics/{irt_num}pl_irt_{quiz_num}.csv'))

(
  joblib.dump([irt_model, irt_fit],
              here(f'joblib_models/{irt_num}pl_irt_{quiz_num}_modfit.joblib'),
              compress = 3)
)
```

```{python}
irt_diagnose['R_hat'].sort_values(ascending = False).head()
```

```{python}
iirt = az.from_cmdstanpy(
    posterior = irt_fit,
    posterior_predictive = ['y_rep'],
    observed_data = {'Y': y_sub.drop(columns = 'name')},
    log_likelihood = {'Y': 'log_lik'})

name_mapping = {'y_rep': 'Y'}
iirt = iirt.rename(name_dict = name_mapping, groups = ["posterior_predictive"])
```

## Model Fit

```{python}
az.loo(iirt)
```

```{python}
az.waic(iirt)
```

## Difficulty Visuals

```{python}
az.plot_trace(iirt,
              var_names = ('^b'),
              filter_vars = 'regex'
)
plt.show()
# plt.clf()
```

## Discrimination Visuals

```{python}
#| eval: false
#| echo: true

# only for 2pl | 3pl

az.plot_trace(iirt,
              var_names = ('^a'),
              filter_vars = 'regex'
)
plt.show()
# plt.clf()
```

## Guessing Visuals

```{python}
# only for 3pl

# az.plot_trace(iirt,
#                 var_names = 'c')
# plt.show()
# plt.clf()
```

## Eta Visuals

```{python}
az.plot_trace(iirt.posterior["eta"].isel(eta_dim_0 = slice(0, 4),
                                          eta_dim_1 = slice(None)),
               var_names = 'eta')
plt.show()
# plt.clf()
```

## Student Ability (Theta) Visuals

```{python}
az.plot_trace(iirt,
              var_names = ('^theta'),
              filter_vars = 'regex'
)
plt.show()
# plt.clf()
```

## PPP Value Visuals

```{python}
az.plot_ppc(iirt,
            data_pairs = {'Y': 'Y'},
            num_pp_samples = 1000)
plt.show()
# plt.clf()
```

```{python}
az.plot_ppc(iirt,
            data_pairs = {'Y': 'Y'},
            num_pp_samples = 1000,
            kind = 'cumulative')
plt.show()
# plt.clf()
```

```{python}
az.plot_bpv(iirt,
            kind = 't_stat', 
            t_stat = 'mean')
plt.show()
# plt.clf()
```

```{python}
az.plot_bpv(iirt,
            kind = 't_stat', 
            t_stat = 'std')
plt.show()
# plt.clf()
```

## Number of Items Correct Visual

```{python}
az.plot_forest(iirt.posterior["prob_correct"].isel(prob_correct_dim_0 = slice(0, 4),
                                                    prob_correct_dim_1 = slice(None)
                                                    ),
               var_names = 'prob_correct',
               colors = jpcolor)
plt.show()
# plt.clf()
```

## IRT DataFrame

```{python}
irtdf = irt_fit.draws_pd()
```

## Student Ability & Uncertainty

```{python}
ability = irtdf.filter(regex = 'theta')
ability = pd.DataFrame({
  'mean': ability.mean(),
  'std': ability.std(),
  'q_lower': q_lower(ability),
  'q_upper': q_upper(ability)
}).reset_index()

ability['stu'] = ability['index'].str.replace('theta[', '')
ability['stu'] = ability['stu'].str.replace(']', '')
ability = ability.drop(columns = 'index')
ability.head()

pn.ggplot.show(
  pn.ggplot(ability,
            pn.aes('stu',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .3,
                     color = jpcolor)
  + pn.geom_hline(yintercept = 0,
                  color = 'black',
                  linetype = 'dashed')
  + pn.labs(title = 'Ability Parameter for Each Student',
            x = 'Student',
            y = 'Ability')
  + pn.theme(axis_text_x = pn.element_blank())
)
```

## Difficulty & Uncertainty

b = difficulty 

0 = average difficulty, 2+ = very hard, -2 = very easy

```{python}
diff = irtdf.filter(regex = '^b.*]$')
diff = pd.DataFrame({
  'mean': diff.mean(),
  'std': diff.std(),
  'q_lower': q_lower(diff),
  'q_upper': q_upper(diff)
}).reset_index()

diff['item'] = diff['index'].str.replace('b[', '')
diff['item'] = diff['item'].str.replace(']', '')
diff = diff.drop(columns = 'index')
diff.head()

pn.ggplot.show(
  pn.ggplot(diff,
            pn.aes('item',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .3,
                     color = jpcolor)
  # + pn.geom_hline(yintercept = 0,
  #                 color = 'black',
  #                 linetype = 'dashed')
  + pn.labs(title = 'Difficulty Parameter for Each Item',
            x = 'Item',
            y = 'Difficulty')
  + pn.theme(axis_text_x = pn.element_blank())
)
```

## Discrimination & Uncertainty

For 2pl & 3pl IRT models

a = discrimination (differentiate between individuals w/ different ability levels (theta))

high value = strong discrimination, low value = weak discrimination

negative = low theta individuals more likely to get responses correct

```{python}
#| eval: false
#| echo: true

dis = irtdf.filter(regex = '^a.*]$')
dis = pd.DataFrame({
  'mean': dis.mean(),
  'std': dis.std(),
  'q_lower': q_lower(dis),
  'q_upper': q_upper(dis)
}).reset_index()

dis['item'] = dis['index'].str.replace('a[', '')
dis['item'] = dis['item'].str.replace(']', '')
dis = dis.drop(columns = 'index')
dis.head()

pn.ggplot.show(
  pn.ggplot(dis,
            pn.aes('item',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .3,
                     color = jpcolor)
  # + pn.geom_hline(yintercept = 0,
  #                 color = 'black',
  #                 linetype = 'dashed')
  + pn.labs(title = 'Discrimination Parameter for Each Item',
            x = 'Item',
            y = 'Discrimination')
  + pn.theme(axis_text_x = pn.element_blank())
)
```

## Guessing

3pl models only

higher value = easier to guess

```{python}
#| eval: false
#| echo: true

guess = irtdf.filter(regex = '^c.*]$')
guess = pd.DataFrame({
  'mean': guess.mean(),
  'std': guess.std(),
  'q_lower': q_lower(guess),
  'q_upper': q_upper(guess)
}).reset_index()

guess['item'] = guess['index'].str.replace('c[', '')
guess['item'] = guess['item'].str.replace(']', '')
guess = guess.drop(columns = 'index')
guess.head()

pn.ggplot.show(
  pn.ggplot(guess,
            pn.aes('item',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .3,
                     color = jpcolor)
  # + pn.geom_hline(yintercept = 0,
  #                 color = 'black',
  #                 linetype = 'dashed')
  + pn.labs(title = 'Difficulty Parameter for Each Item',
            x = 'Item',
            y = 'Difficulty')
  + pn.theme(axis_text_x = pn.element_blank())
)
```

## Replicated Data

```{python}
yirt = irtdf.filter(regex = '^y_rep')
yirt.head()

yirt_prob = pd.DataFrame({
  'mean': yirt.mean(),
  'std': yirt.std(),
  'q_lower': q_lower(yirt),
  'q_upper': q_upper(yirt)
}).reset_index()

yirt_prob['index'] = yirt_prob['index'].str.replace('y_rep[', '')
yirt_prob['index'] = yirt_prob['index'].str.replace(']', '')
yirt_prob[['stu', 'item']] = yirt_prob['index'].str.split(pat = ',', expand = True)
yirt_prob = yirt_prob[['stu', 'item', 'mean', 'std', 'q_lower', 'q_upper']]
yirt_prob[['stu', 'item']] = yirt_prob[['stu', 'item']].astype(int)
yirt_prob['correct'] = np.where(yirt_prob['mean'] >= .5, 1, 0)

# proportion that got each item correct
yirt_prob.groupby('item')['correct'].sum()

pn.ggplot.show(
  pn.ggplot(yirt_prob,
            pn.aes('stu',
                   'mean'))
  + pn.geom_point(pn.aes(color = 'factor(item)'),
                  alpha = .5)
  # + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
  #                           ymax = 'q_upper',
  #                           color = 'factor(item)'),
  #                    alpha = .1)
  + pn.geom_hline(yintercept = .5,
                  color = 'black',
                  linetype = 'dashed')
  + pn.labs(title = 'Probability Student Gets Items Correct',
            x = 'Student',
            y = 'Probability')
  + pn.theme(axis_text_x = pn.element_blank())
)
```

```{python}
yirt_wide = (
  yirt_prob
  .pivot(
    index = 'stu',
    columns = 'item',
    values = 'correct')
  .reset_index(drop = True)
)

yirt_wide.columns = [f'item{i+1}' for i in np.arange(yirt_wide.shape[1])]
yirt_wide = yirt_wide.reset_index()
yirt_wide = yirt_wide.rename(columns = {'index': 'stu'})
yirt_wide['stu'] = yirt_wide['stu'] + 1
# yirt_wide.head()
```

```{python}
irt_means = [ppp_func(df = yirt_prob, item_num = i, stat = 'mean') for i in np.arange(1, (y_describe.shape[1]))]
irt_stds = [ppp_func(df = yirt_prob, item_num = i, stat = 'std') for i in np.arange(1, (y_describe.shape[1]))]

ppp_irt = pd.DataFrame({'means': pd.Series(irt_means),
                       'stds': pd.Series(irt_stds)})

ppp_irt = ppp_irt.reset_index()
ppp_irt = ppp_irt.rename(columns = {'index': 'item'})
ppp_irt['item'] = ppp_irt['item'] + 1

# ppp_irt.head()
# y_describe
```

```{python}
pn.ggplot.show(
  pn.ggplot(ppp_irt, pn.aes('item', 'means'))
  + pn.geom_point(color = jpcolor,
                  size = 2)
  + pn.geom_hline(yintercept = .5, linetype = 'dashed')
  + pn.geom_hline(yintercept = .025, linetype = 'dotted')
  + pn.geom_hline(yintercept = .975, linetype = 'dotted')
  + pn.scale_x_continuous(limits = [1, ppp_irt['item'].max() + 1],
                          breaks = np.arange(1, ppp_irt['item'].max() + 1))
  + pn.scale_y_continuous(limits = [0, 1.01],
                          breaks = np.arange(0, 1.01, .1))
  + pn.theme_light()
)
```

```{python}
pn.ggplot.show(
  pn.ggplot(ppp_irt, pn.aes('item', 'stds'))
  + pn.geom_point(color = jpcolor,
                  size = 2)
  + pn.geom_hline(yintercept = .5, linetype = 'dashed')
  + pn.geom_hline(yintercept = .025, linetype = 'dotted')
  + pn.geom_hline(yintercept = .975, linetype = 'dotted')
  + pn.scale_x_continuous(limits = [1, ppp_irt['item'].max() + 1],
                          breaks = np.arange(1, ppp_irt['item'].max() + 1))
  + pn.scale_y_continuous(limits = [0, 1.01],
                          breaks = np.arange(0, 1.01, .1))
  + pn.theme_light()
)
```

# Diagnostic Model

```{python}
#| include: false

stan_dict = {
  'J': y_sub.drop(columns = 'name').shape[0],
  'I': y_sub.drop(columns = 'name').shape[1],
  'C': alpha.shape[0],
  'K': q.shape[1],
  'Y': np.array(y_sub.drop(columns = 'name')),
  'Q': np.array(q),
  'alpha': np.array(alpha)
}

dcm_file = os.path.join(here('stan_models/lcdm.stan'))
dcm_model = CmdStanModel(stan_file = dcm_file,
                         cpp_options={'STAN_THREADS': 'TRUE'})

np.random.seed(12345)
dcm_fit = dcm_model.sample(data = stan_dict,
                        show_console = True,
                        chains = 4,
                        # adapt_delta = .95,
                        iter_warmup = 2000,
                        iter_sampling = 2000)

dcm_diagnose = pd.DataFrame(dcm_fit.summary())
```

```{python}
#| eval: true
#| echo: true

dcm_diagnose.to_csv(here(f'diagnostics/{dcm_type}_{quiz_num}.csv'))

(
  joblib.dump([dcm_model, dcm_fit],
              here(f'joblib_models/{dcm_type}_{quiz_num}_modfit.joblib'),
              compress = 3)
)
```

```{python}
dcm_diagnose['R_hat'].sort_values(ascending = False).head()
```

```{python}
idcm = az.from_cmdstanpy(
    posterior = dcm_fit,
    posterior_predictive = ['y_rep'],
    observed_data = {'Y': y.filter(regex = 'item')},
    log_likelihood = {'Y': 'eta'})

idcm = idcm.rename(name_dict = name_mapping, groups = ["posterior_predictive"])

```

### Model Fit

```{python}
az.loo(idcm)
```

```{python}
az.waic(idcm)
```

## Class Membership Visuals

```{python}
az.plot_trace(idcm,
                var_names = 'nu')
plt.show()
# plt.clf()
```

## Pi Matrix Visuals

```{python}
az.plot_trace(idcm,
                var_names = 'pi')
plt.show()
# plt.clf()
```

## Beta Coefficient Visuals

```{python}
az.plot_trace(idcm,
                var_names = 'beta0')
plt.show()
# plt.clf()
```

```{python}
az.plot_trace(idcm,
                var_names = 'beta1')
plt.show()
# plt.clf()
```

```{python}
az.plot_trace(idcm,
                var_names = 'beta2')
plt.show()
# plt.clf()
```

```{python}
az.plot_trace(idcm,
                var_names = 'beta12')
plt.show()
# plt.clf()
```

### Attribute Mastery Per Class Visual

```{python}
az.plot_forest(idcm.posterior["prob_resp_class"].isel(prob_resp_class_dim_0 = slice(0, 4),
                                                    prob_resp_class_dim_1 = slice(None)
                                                    ),
               var_names = 'prob_resp_class',
               colors = jpcolor)
plt.show()
# plt.clf()
```

### Attribute Mastery Per Student Visual

```{python}
az.plot_forest(idcm.posterior["prob_resp_attr"].isel(prob_resp_attr_dim_0 = slice(0, 4),
                                                    prob_resp_attr_dim_1 = slice(None)
                                                    ),
               var_names = 'prob_resp_attr',
               colors = jpcolor)
plt.show()
# plt.clf()
```

## PPP Visuals

```{python}
az.plot_ppc(idcm,
            data_pairs = {'Y': 'Y'},
            num_pp_samples = 1000)
plt.show()
# plt.clf()
```

```{python}
az.plot_ppc(idcm,
            data_pairs = {'Y': 'Y'},
            num_pp_samples = 1000,
            kind = 'cumulative')
plt.show()
# plt.clf()
```

```{python}
az.plot_bpv(idcm,
            kind = 't_stat', 
            t_stat = 'mean')
plt.show()
# plt.clf()
```

```{python}
az.plot_bpv(idcm,
            kind = 't_stat', 
            t_stat = 'std')
plt.show()
# plt.clf()
```

## Pandas Dataframe

```{python}
dcmdf = dcm_fit.draws_pd()
```

## Pi Matrix

```{python}
pi_mat = dcmdf.filter(regex = 'pi')
pi_mat = pd.DataFrame({
  'mean': pi_mat.mean(),
  'std': pi_mat.std(),
  'q_lower': q_lower(pi_mat),
  'q_upper': q_upper(pi_mat)
}).reset_index()

pi_mat['index'] = pi_mat['index'].str.replace('pi[', '')
pi_mat['index'] = pi_mat['index'].str.replace(']', '')
pi_mat[['item', 'lat_class']] = pi_mat['index'].str.split(',', expand = True)
pi_mat[['item', 'lat_class']] = pi_mat[['item', 'lat_class']].astype(int)
pi_mat = pi_mat[['item', 'lat_class', 'mean', 'std', 'q_lower', 'q_upper']]
pi_mat.head()

pn.ggplot.show(
  pn.ggplot(pi_mat,
            pn.aes('factor(item)',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .1)
  + pn.geom_hline(yintercept = .5,
                  color = 'black',
                  linetype = 'dashed')
  + pn.facet_wrap('lat_class')
  + pn.labs(title = 'Probability That Latent Class Gets Items Correct',
            x = 'Item',
            y = 'Probability')
)
```

```{python}
pn.ggplot.show(
  pn.ggplot(pi_mat,
            pn.aes('factor(item)',
                   'std'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.facet_wrap('lat_class')
  + pn.labs(title = 'Standard Deviation For Each Item By Latent Class',
            x = 'Item',
            y = 'Standard Deviation')
)
```

### Beta Coefficients

```{python}

beta_df = dcmdf.filter(regex = 'beta')
beta_df = pd.DataFrame({
  'mean': beta_df.mean(),
  'std': beta_df.std(),
  'q_lower': q_lower(beta_df),
  'q_upper': q_upper(beta_df)
}).reset_index()

beta_df['index'] = beta_df['index'].str.replace(']', '')
beta_df[['var', 'item']] = beta_df['index'].str.split('[', expand = True)
beta_df['item'] = beta_df['item'].astype(int)
beta_df = beta_df[['item', 'var', 'mean', 'std', 'q_lower', 'q_upper']]
beta_df.head()

pn.ggplot.show(
  pn.ggplot(beta_df,
            pn.aes('factor(item)',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .1)
  + pn.facet_wrap('var')
  + pn.labs(title = 'Coefficient Value Per Variable',
            x = 'Item',
            y = 'Coefficient')
)
```

```{python}
pn.ggplot.show(
  pn.ggplot(beta_df,
            pn.aes('factor(item)',
                   'std'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.facet_wrap('var')
  + pn.labs(title = 'Standard Deviation For Coefficient Value Per Variable',
            x = 'Item',
            y = 'Standard Deviation')
)
```

### Attribute Mastery & Uncertainty

```{python}
attr_df = dcmdf.filter(regex = '^prob_resp_attr')
attr_df = pd.DataFrame({
  'mean': attr_df.mean(),
  'std': attr_df.std(),
  'q_lower': q_lower(attr_df),
  'q_upper': q_upper(attr_df)
}).reset_index()

attr_df['index'] = attr_df['index'].str.replace('prob_resp_attr[', '')
attr_df['index'] = attr_df['index'].str.replace(']', '')
attr_df[['stu', 'attr']] = attr_df['index'].str.split(',', expand = True)
attr_df[['stu', 'attr']] = attr_df[['stu', 'attr']].astype(int)
attr_df = attr_df[['stu', 'attr', 'mean', 'std', 'q_lower', 'q_upper']]
# attr_df.head()

pn.ggplot.show(
  pn.ggplot(attr_df,
            pn.aes('stu',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .1)
  + pn.geom_hline(yintercept = mastery_prob,
                  linetype = 'dashed')
  + pn.facet_wrap('attr')
  + pn.labs(title = 'Attribute Mastery Per Student',
            x = 'Students',
            y = 'Probability')
)
```

```{python}
pn.ggplot.show(
  pn.ggplot(attr_df,
            pn.aes('stu',
                   'std'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.facet_wrap('attr')
  + pn.labs(title = 'Standard Deviation Per Student For Each Attribute',
            x = 'Students',
            y = 'Standard Deviation')
)
```

```{python}
attr_df['mastery'] = np.where(attr_df['mean'] > mastery_prob, 1, 0)
attr_df['proficiency'] = np.where(attr_df['mean'] > prof_prob, 1, 0)

# attr_df.head()

attr_df.groupby('attr')['mastery'].value_counts().reset_index()
attr_df.groupby('attr')['proficiency'].value_counts().reset_index()

attr_mastery = attr_df.pivot(index = 'stu',
              columns = 'attr',
              values = 'mastery').reset_index()
attr_mastery = attr_mastery.rename(columns = {1: 'attr1',
                                              2: 'attr2'})
# attr_mastery.head()
```

```{python}
#| eval: true
#| echo: true

# INCLUDE THE NAMES FOR THE ATTRIBUTES HERE FOR MASTERY
attr_mastery['attr1'] = np.where(attr_mastery['attr1'] == 1, '', '')
attr_mastery['attr2'] = np.where(attr_mastery['attr2'] == 1, '', '')
attr_mastery.to_csv(f'student_data/attribute_mastery_{quiz_num}.csv')
```

```{python}
attr_prof = attr_df.pivot(index = 'stu',
              columns = 'attr',
              values = 'mastery').reset_index()
attr_prof = attr_prof.rename(columns = {1: 'attr1',
                                        2: 'attr2'})
# attr_prof.head()
```

```{python}
#| eval: true
#| echo: true

# INCLUDE THE NAMES FOR THE ATTRIBUTES HERE FOR PROFICIENCY
attr_prof['attr1'] = np.where(attr_prof['attr1'] == 1, '', '')
attr_prof['attr2'] = np.where(attr_prof['attr2'] == 1, '', '')
attr_prof.to_csv(f'student_data/attribute_proficiency_{quiz_num}.csv')
```

### Attribute Mastery Per Class

```{python}
attr_class_df = dcmdf.filter(regex = '^prob_resp_class')
attr_class_df = pd.DataFrame({
  'mean': attr_class_df.mean(),
  'std': attr_class_df.std(),
  'q_lower': q_lower(attr_class_df),
  'q_upper': q_upper(attr_class_df)
}).reset_index()

attr_class_df['index'] = attr_class_df['index'].str.replace('prob_resp_class[', '')
attr_class_df['index'] = attr_class_df['index'].str.replace(']', '')
attr_class_df[['stu', 'lat_class']] = attr_class_df['index'].str.split(',', expand = True)
attr_class_df[['stu', 'lat_class']] = attr_class_df[['stu', 'lat_class']].astype(int)
attr_class_df = attr_class_df[['stu', 'lat_class', 'mean', 'std', 'q_lower', 'q_upper']]
# attr_class_df.head()

pn.ggplot.show(
  pn.ggplot(attr_class_df,
            pn.aes('stu',
                   'mean'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
                            ymax = 'q_upper'),
                     alpha = .1)
  + pn.geom_hline(yintercept = .5,
                  color = 'black',
                  linetype = 'dashed')
  + pn.facet_wrap('lat_class')
  + pn.labs(title = 'Probability Per Student In Each Latent Class',
            x = 'Students',
            y = 'Probability')
)
```

```{python}
pn.ggplot.show(
  pn.ggplot(attr_class_df,
            pn.aes('stu',
                   'std'))
  + pn.geom_point(alpha = .5,
                  color = jpcolor)
  + pn.facet_wrap('lat_class')
  + pn.labs(title = 'Standard Deviation Per Student For Each Latent Class',
            x = 'Students',
            y = 'Standard Deviation')
)
```

## PPP Calculations

```{python}
ydcm = dcmdf.filter(regex = '^y_rep')

ydcm_prob = pd.DataFrame({
  'mean': ydcm.mean(),
  'std': ydcm.std(),
  'q_lower': q_lower(ydcm),
  'q_upper': q_upper(ydcm)
}).reset_index()

ydcm_prob['index'] = ydcm_prob['index'].str.replace('y_rep[', '')
ydcm_prob['index'] = ydcm_prob['index'].str.replace(']', '')
ydcm_prob[['stu', 'item']] = ydcm_prob['index'].str.split(pat = ',', expand = True)
ydcm_prob = ydcm_prob[['stu', 'item', 'mean', 'std', 'q_lower', 'q_upper']]
ydcm_prob[['stu', 'item']] = ydcm_prob[['stu', 'item']].astype(int)
ydcm_prob['correct'] = np.where(ydcm_prob['mean'] >= .5, 1, 0)

pn.ggplot.show(
  pn.ggplot(ydcm_prob,
            pn.aes('stu',
                   'mean'))
  + pn.geom_point(pn.aes(color = 'factor(item)'),
                  alpha = .5)
  # + pn.geom_errorbar(pn.aes(ymin = 'q_lower',
  #                           ymax = 'q_upper',
  #                           color = 'factor(item)'),
  #                    alpha = .1)
  + pn.geom_hline(yintercept = .5,
                  color = 'black',
                  linetype = 'dashed')
  + pn.labs(title = 'Probability Student Gets Items Correct',
            x = 'Student',
            y = 'Probability')
  + pn.theme(axis_text_x = pn.element_blank())
)
```

```{python}
ydcm_wide = (
  ydcm_prob
  .pivot(
    index = 'stu',
    columns = 'item',
    values = 'correct')
  .reset_index(drop = True)
)

ydcm_wide.columns = [f'item{i+1}' for i in np.arange(ydcm_wide.shape[1])]
ydcm_wide = ydcm_wide.reset_index()
ydcm_wide = ydcm_wide.rename(columns = {'index': 'stu'})
ydcm_wide['stu'] = ydcm_wide['stu'] + 1
# ydcm_wide.head()
```


```{python}
ydcm_wide['total_correct'] = ydcm_wide.drop(columns = 'stu').sum(axis = 1)
ydcm_wide['actual_correct'] = y_sub.drop(columns = 'name').sum(axis = 1)

ydcm_compare = ydcm_wide[['stu', 'total_correct', 'actual_correct']].melt(id_vars = 'stu')
ydcm_compare_count = ydcm_compare.groupby('variable')['value'].value_counts().reset_index()

pn.ggplot.show(
  pn.ggplot(ydcm_compare_count,
            pn.aes('factor(value)',
                   'count'))
  + pn.geom_point(pn.aes(color = 'variable'))
)
```

```{python}
ydcm_compare_actual = ydcm_compare.loc[ydcm_compare['variable'] == 'actual_correct', 'value'].sort_values()
ydcm_compare_predict = ydcm_compare.loc[ydcm_compare['variable'] == 'total_correct', 'value'].sort_values()

ydcm_compare_actual = pd.Categorical(ydcm_compare_actual, ordered = True)
ydcm_compare_predict = pd.Categorical(ydcm_compare_predict, ordered = True)


count_tabs = pd.crosstab(ydcm_compare_actual,
                         ydcm_compare_predict)
# count_tabs

# from scipy.stats import chisquare
from scipy.stats import chi2_contingency
chi2_contingency(observed = count_tabs)
```

### Overall PPP Values

```{python}
overall_ppp(ydcm_prob, 'mean')
```

```{python}
# overall, model fits pretty well

overall_ppp(ydcm_prob, 'std')
```

### Item Specific PPP Values

```{python}
dcm_means = [ppp_func(df = ydcm_prob,
                      item_num = i,
                      stat = 'mean') for i in np.arange(1,
                                                        (y_describe.shape[1]))]
dcm_stds = [ppp_func(df = ydcm_prob,
                     item_num = i,
                     stat = 'std') for i in np.arange(1,
                                                      (y_describe.shape[1]))]

ppp_dcm = pd.DataFrame({'means': pd.Series(dcm_means),
                       'stds': pd.Series(dcm_stds)})

ppp_dcm = ppp_dcm.reset_index()
ppp_dcm = ppp_dcm.rename(columns = {'index': 'item'})
ppp_dcm['item'] = ppp_dcm['item'] + 1

gt.show(gt(ppp_dcm))
```

```{python}
pn.ggplot.show(
  pn.ggplot(ppp_dcm, pn.aes('item', 'means'))
  + pn.geom_point(color = jpcolor,
                  size = 2)
  + pn.geom_hline(yintercept = .5, linetype = 'dashed')
  + pn.geom_hline(yintercept = .025, linetype = 'dotted')
  + pn.geom_hline(yintercept = .975, linetype = 'dotted')
  + pn.scale_x_continuous(limits = [1, ppp_dcm['item'].max() + 1],
                          breaks = np.arange(1, ppp_dcm['item'].max() + 1))
  + pn.scale_y_continuous(limits = [0, 1.01],
                          breaks = np.arange(0, 1.01, .1))
  + pn.theme_light()
)
```

```{python}

pn.ggplot.show(
  pn.ggplot(ppp_dcm, pn.aes('item', 'stds'))
  + pn.geom_point(color = jpcolor,
                  size = 2)
  + pn.geom_hline(yintercept = .5, linetype = 'dashed')
  + pn.geom_hline(yintercept = .025, linetype = 'dotted')
  + pn.geom_hline(yintercept = .975, linetype = 'dotted')
  + pn.scale_x_continuous(limits = [1, ppp_dcm['item'].max() + 1],
                          breaks = np.arange(1, ppp_dcm['item'].max() + 1))
  + pn.scale_y_continuous(limits = [0, 1.01],
                          breaks = np.arange(0, 1.01, .1))
  + pn.theme_light()
)
```
